{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500c1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['bmh'])\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.model_selection import RepeatedKFold,train_test_split\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eb53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43712e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fbe3e19",
   "metadata": {},
   "source": [
    "# Comparing to random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194a42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "#     x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "#     pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "#     param_grid = [\n",
    "#     {'classifier' : [RandomForestClassifier()],\n",
    "#     'classifier__criterion':('gini','entropy'),\n",
    "#     'classifier__class_weight':('balanced','auto')}]\n",
    "#     clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "#     clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "#     best_clf=clf.best_estimator_\n",
    "#     y_valid=best_clf.predict(data_val[x_column_list])\n",
    "    \n",
    "#     report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "    \n",
    "#     F1_0_class_RF=report_RF['0.0']['f1-score']\n",
    "#     F1_1_class_RF=report_RF['1.0']['f1-score']\n",
    "    \n",
    "#     pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "#     param_grid = [\n",
    "#     {'classifier' : [RandomForestClassifier()],\n",
    "#     'classifier__criterion':('gini','entropy'),\n",
    "#     'classifier__class_weight':('balanced','auto')}]\n",
    "#     totalF1_0=[]\n",
    "#     totalF1_1=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "#         RD1=pd.DataFrame(RD1)\n",
    "#         RD1.columns =data[x_column_list].columns\n",
    "#         RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD11.iloc[0:data_train.shape[0],0:len(x_column_list)], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD11.iloc[data_train.shape[0]:,0:len(x_column_list)])\n",
    "#         report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0.append(report_Random1 ['0.0']['f1-score'])\n",
    "#         totalF1_1.append(report_Random1 ['1.0']['f1-score'])    \n",
    "#     r1=pd.DataFrame()\n",
    "#     r1['0']= totalF1_0\n",
    "#     r1['1']= totalF1_1\n",
    "#     EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario2\n",
    "#     totalF1_0_2=[]\n",
    "#     totalF1_1_2=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "#         RD2.columns=data[x_column_list].columns\n",
    "#         for col in data[x_column_list].columns:\n",
    "#             dd=np.where(data[x_column_list][col]==0)[0]\n",
    "#             if len(dd)>0:\n",
    "#                 RD2[col][dd]=0\n",
    "#         RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD22[x_column_list][0:data_train.shape[0]], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD22[x_column_list][data_train.shape[0]:])\n",
    "#         report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_2.append(report_Random2['0.0']['f1-score'])\n",
    "#         totalF1_1_2.append(report_Random2['1.0']['f1-score'])\n",
    "#     r2=pd.DataFrame()\n",
    "#     r2['0']= totalF1_0_2\n",
    "#     r2['1']= totalF1_1_2\n",
    "#     EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario3\n",
    "#     totalF1_0_3=[]\n",
    "#     totalF1_1_3=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         YR=np.random.permutation(data['y_b'].values)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(data_val[x_column_list])\n",
    "#         report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_3.append(report_Random3['0.0']['f1-score'])\n",
    "#         totalF1_1_3.append(report_Random3['1.0']['f1-score'])\n",
    "#     r3=pd.DataFrame()\n",
    "#     r3['0']= totalF1_0_3\n",
    "#     r3['1']= totalF1_1_3\n",
    "#     EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #Senario4\n",
    "#     totalF1_0_4=[]\n",
    "#     totalF1_1_4=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         DR=data[x_column_list].sample(frac=1)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "#         report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_4.append(report_Random4['0.0']['f1-score'])\n",
    "#         totalF1_1_4.append(report_Random4['1.0']['f1-score'])\n",
    "#     r4=pd.DataFrame()\n",
    "#     r4['0']= totalF1_0_4\n",
    "#     r4['1']= totalF1_1_4\n",
    "#     EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     ev_value=[EV1,EV2,EV3,EV4]\n",
    "#     return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef4e3a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "    x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "    pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "    param_grid = [\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__criterion':('gini','entropy'),\n",
    "    'classifier__class_weight':('balanced','auto')}]\n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "    clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(data_val[x_column_list])\n",
    "\n",
    "    report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "    F1_0_class_RF=report_RF['0.0']['f1-score']\n",
    "    F1_1_class_RF=report_RF['1.0']['f1-score']\n",
    "\n",
    "    totalF1_0=[]\n",
    "    totalF1_1=[]\n",
    "    for i in range(1,NumofR):\n",
    "        RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "        RD1=pd.DataFrame(RD1)\n",
    "        RD1.columns =data[x_column_list].columns\n",
    "        RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(RD11.iloc[data_train.index,0:len(x_column_list)], data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(RD11.iloc[data_val.index,0:len(x_column_list)])\n",
    "        report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0.append(report_Random1 ['0.0']['f1-score'])\n",
    "        totalF1_1.append(report_Random1 ['1.0']['f1-score'])    \n",
    "    r1=pd.DataFrame()\n",
    "    r1['0']= totalF1_0\n",
    "    r1['1']= totalF1_1\n",
    "    EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ (r1.shape[0])\n",
    "    #senario2\n",
    "    totalF1_0_2=[]\n",
    "    totalF1_1_2=[]\n",
    "    for i in range(1,NumofR):\n",
    "        RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "        RD2.columns=data[x_column_list].columns\n",
    "        for col in data[x_column_list].columns:\n",
    "            dd=np.where(data[x_column_list][col]==0)[0]\n",
    "            if len(dd)>0:\n",
    "                RD2[col][dd]=0\n",
    "        RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(RD22.iloc[data_train.index][x_column_list], data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(RD22.iloc[data_val.index][x_column_list])\n",
    "        report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_2.append(report_Random2['0.0']['f1-score'])\n",
    "        totalF1_1_2.append(report_Random2['1.0']['f1-score'])\n",
    "    r2=pd.DataFrame()\n",
    "    r2['0']= totalF1_0_2\n",
    "    r2['1']= totalF1_1_2\n",
    "    EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ (r2.shape[0])\n",
    "    #senario3\n",
    "    totalF1_0_3=[]\n",
    "    totalF1_1_3=[]\n",
    "    for i in range(1,NumofR):\n",
    "        YR=np.random.permutation(data['y_b'].values)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(data_val[x_column_list])\n",
    "        report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_3.append(report_Random3['0.0']['f1-score'])\n",
    "        totalF1_1_3.append(report_Random3['1.0']['f1-score'])\n",
    "    r3=pd.DataFrame()\n",
    "    r3['0']= totalF1_0_3\n",
    "    r3['1']= totalF1_1_3\n",
    "    #print(totalF1_0_3)\n",
    "    print(r3.shape[0])\n",
    "    \n",
    "    EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ (r3.shape[0])\n",
    "    #Senario4\n",
    "    totalF1_0_4=[]\n",
    "    totalF1_1_4=[]\n",
    "    for i in range(1,NumofR):\n",
    "        DR=data[x_column_list].sample(frac=1)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "        report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_4.append(report_Random4['0.0']['f1-score'])\n",
    "        totalF1_1_4.append(report_Random4['1.0']['f1-score'])\n",
    "    r4=pd.DataFrame()\n",
    "    r4['0']= totalF1_0_4\n",
    "    r4['1']= totalF1_1_4\n",
    "    EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ (r4.shape[0])\n",
    "    ev_value=[EV1,EV2,EV3,EV4]\n",
    "\n",
    "\n",
    "    return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f43c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=RepeatedKFold(n_splits=10,n_repeats=3, random_state=100)\n",
    "th=0.05\n",
    "q=0.7\n",
    "NumofR=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bffb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_response='/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/disease_response/'  \n",
    "path_x = '/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/compare_random/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f294b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield_per_meter\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(196, 2)\n",
      "(196, 226)\n",
      "199\n",
      "[0.23115577889447236, 0.1708542713567839, 0.23618090452261306, 0.3417085427135678]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(196, 2)\n",
      "(196, 257)\n",
      "199\n",
      "[0.07035175879396985, 0.07035175879396985, 0.1708542713567839, 0.1457286432160804]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(196, 2)\n",
      "(196, 487)\n",
      "199\n",
      "[0.21608040201005024, 0.32160804020100503, 0.27638190954773867, 0.3065326633165829]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(196, 2)\n",
      "(196, 110)\n",
      "199\n",
      "[0.03015075376884422, 0.135678391959799, 0.035175879396984924, 0.04522613065326633]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(196, 2)\n",
      "(196, 44)\n",
      "199\n",
      "[0.25125628140703515, 0.1658291457286432, 0.4221105527638191, 0.2864321608040201]\n",
      "no_tuber_scab\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(231, 2)\n",
      "(214, 226)\n",
      "199\n",
      "[0.0, 0.05527638190954774, 0.11557788944723618, 0.06532663316582915]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(231, 2)\n",
      "(214, 257)\n",
      "199\n",
      "[0.0, 0.06532663316582915, 0.09045226130653267, 0.06030150753768844]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(231, 2)\n",
      "(214, 487)\n",
      "199\n",
      "[0.0, 0.20100502512562815, 0.07537688442211055, 0.01507537688442211]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(231, 2)\n",
      "(214, 110)\n",
      "199\n",
      "[0.0, 0.0, 0.005025125628140704, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(231, 2)\n",
      "(214, 44)\n",
      "199\n",
      "[0.005025125628140704, 0.10552763819095477, 0.18592964824120603, 0.11557788944723618]\n",
      "pctg_black_scurf\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(231, 2)\n",
      "(214, 226)\n",
      "199\n",
      "[1.0, 1.0, 0.9899497487437185, 0.9949748743718593]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(231, 2)\n",
      "(214, 257)\n",
      "199\n",
      "[1.0, 1.0, 0.9849246231155779, 1.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(231, 2)\n",
      "(214, 487)\n",
      "199\n",
      "[1.0, 1.0, 1.0, 1.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(231, 2)\n",
      "(214, 110)\n",
      "199\n",
      "[1.0, 1.0, 0.9899497487437185, 0.9949748743718593]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(231, 2)\n",
      "(214, 44)\n",
      "199\n",
      "[1.0, 1.0, 0.9798994974874372, 0.9849246231155779]\n",
      "yield_per_plant\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(219, 2)\n",
      "(219, 226)\n",
      "199\n",
      "[0.45226130653266333, 0.36180904522613067, 0.33668341708542715, 0.40703517587939697]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(219, 2)\n",
      "(219, 257)\n",
      "199\n",
      "[0.07035175879396985, 0.04020100502512563, 0.07537688442211055, 0.09547738693467336]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(219, 2)\n",
      "(219, 487)\n",
      "199\n",
      "[0.07035175879396985, 0.05527638190954774, 0.07035175879396985, 0.135678391959799]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(219, 2)\n",
      "(219, 110)\n",
      "199\n",
      "[0.4020100502512563, 0.2562814070351759, 0.32160804020100503, 0.34673366834170855]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(219, 2)\n",
      "(219, 44)\n",
      "199\n",
      "[0.01507537688442211, 0.020100502512562814, 0.020100502512562814, 0.010050251256281407]\n",
      "no_tuber_scabpit\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(231, 2)\n",
      "(214, 226)\n",
      "199\n",
      "[0.0, 0.20100502512562815, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(231, 2)\n",
      "(214, 257)\n",
      "199\n",
      "[0.0, 0.07537688442211055, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(231, 2)\n",
      "(214, 487)\n",
      "199\n",
      "[0.0, 0.38190954773869346, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(231, 2)\n",
      "(214, 110)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(231, 2)\n",
      "(214, 44)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "no_tuber_scabsuper\n",
      " 1 _ 1 .csv\n",
      "(219, 225)\n",
      "(231, 2)\n",
      "(214, 226)\n",
      "199\n",
      "[0.0, 0.7738693467336684, 0.24120603015075376, 0.135678391959799]\n",
      " 1 _ 1 .csv\n",
      "(219, 256)\n",
      "(231, 2)\n",
      "(214, 257)\n",
      "199\n",
      "[0.0, 0.06532663316582915, 0.005025125628140704, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(219, 486)\n",
      "(231, 2)\n",
      "(214, 487)\n",
      "199\n",
      "[0.0, 0.7989949748743719, 0.1708542713567839, 0.11055276381909548]\n",
      " 1 _ 1 .csv\n",
      "(219, 109)\n",
      "(231, 2)\n",
      "(214, 110)\n",
      "199\n",
      "[0.020100502512562814, 0.6482412060301508, 0.24120603015075376, 0.21608040201005024]\n",
      " 1 _ 1 .csv\n",
      "(219, 43)\n",
      "(231, 2)\n",
      "(214, 44)\n",
      "199\n",
      "[0.010050251256281407, 0.2814070351758794, 0.11055276381909548, 0.10050251256281408]\n"
     ]
    }
   ],
   "source": [
    "# path_list2 = []\n",
    "# for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "#     for path in dirs:\n",
    "#         path_list2.append(path)\n",
    "# #EV_Value = dict.fromkeys(dirs)\n",
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r') & (file_response[0] != 'O'): \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        #EV_Value[file_response] = dict.fromkeys(dirs)\n",
    "        #writer= pd.ExcelWriter(path_r+'/'+'EV_Value.xlsx', engine='xlsxwriter')\n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                #response.drop(columns=response.columns[2], inplace=True)  \n",
    "                #response=response.drop(columns='Variety2')    \n",
    "                writer= pd.ExcelWriter(path_r+'/'+'EV_Value.xlsx', engine='xlsxwriter')\n",
    "                writer1= pd.ExcelWriter(path_r+'/'+'RMethod1.xlsx', engine='xlsxwriter')\n",
    "                writer2= pd.ExcelWriter(path_r+'/'+'RMethod2.xlsx', engine='xlsxwriter')\n",
    "                writer3= pd.ExcelWriter(path_r+'/'+'RMethod3.xlsx', engine='xlsxwriter')\n",
    "                writer4= pd.ExcelWriter(path_r+'/'+'RMethod4.xlsx', engine='xlsxwriter')\n",
    "                writer5= pd.ExcelWriter(path_r+'/'+'RFresult.xlsx', engine='xlsxwriter')\n",
    "                #writer= pd.ExcelWriter(path_r+'/'+'classification_RF_Random'+'.xlsx', engine='xlsxwriter')   \n",
    "                #EV_Value[file_response] = dict.fromkeys(dirs)\n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(path+'/'+file)  \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                print(data_temp.shape)\n",
    "                                print(response.shape)\n",
    "                                data=pd.merge(response,data_temp,on='Link_ID') \n",
    "                                print(data.shape)\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)\n",
    "                                out_random = Compare_random(data,data_train,data_val,cv,NumofR)\n",
    "                                #output_dic[file] = [out_random[0],out_random[1], out_random[2],out_random[3],out_random[4],out_random[5],out_random[6]]\n",
    "                                fig, axs = plt.subplots(1,4, figsize=(20, 10), facecolor='w', edgecolor='k')\n",
    "                                fig.subplots_adjust(hspace =0.1, wspace=0.2)\n",
    "\n",
    "                                plt.subplot(1,4,1)\n",
    "                                r1=out_random[0]\n",
    "                                plt.scatter(r1['0'],r1['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 1')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,2)\n",
    "                                r2=out_random[1]\n",
    "                                plt.scatter(r2['0'],r2['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 2')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,3)\n",
    "                                r3=out_random[2]\n",
    "                                plt.scatter(r3['0'],r3['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 3')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,4)\n",
    "                                r4=out_random[3]\n",
    "                                plt.scatter(r4['0'],r4['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0--Strategy 4')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.savefig(path_response+file_response+'/'+file_folder+'.png',facecolor='white')\n",
    "                                plt.close()\n",
    "                                print(out_random[4])\n",
    "                                EV_Value= out_random[4]\n",
    "                        pd.DataFrame(EV_Value).to_excel(writer, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r1).to_excel(writer1, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r2).to_excel(writer2, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r3).to_excel(writer3, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r4).to_excel(writer4, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame([out_random[5],out_random[6]]).to_excel(writer5, sheet_name=file_folder, index=True)\n",
    "                writer.save()\n",
    "                writer1.save()\n",
    "                writer2.save()\n",
    "                writer3.save()\n",
    "                writer4.save()\n",
    "                writer5.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e9269a",
   "metadata": {},
   "source": [
    "# Version2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2384e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "#     x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "#     pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "#     param_grid = [\n",
    "#     {'classifier' : [RandomForestClassifier()],\n",
    "#     'classifier__criterion':('gini','entropy'),\n",
    "#     'classifier__class_weight':('balanced','auto')}]\n",
    "#     clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "#     clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "#     best_clf=clf.best_estimator_\n",
    "#     y_valid=best_clf.predict(data_val[x_column_list])\n",
    "\n",
    "#     report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "#     F1_0_class_RF=report_RF['0']['f1-score']\n",
    "#     F1_1_class_RF=report_RF['1']['f1-score']\n",
    "\n",
    "#     totalF1_0=[]\n",
    "#     totalF1_1=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "#         RD1=pd.DataFrame(RD1)\n",
    "#         RD1.columns =data[x_column_list].columns\n",
    "#         RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD11.iloc[data_train.index,0:len(x_column_list)], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD11.iloc[data_val.index,0:len(x_column_list)])\n",
    "#         report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0.append(report_Random1 ['0']['f1-score'])\n",
    "#         totalF1_1.append(report_Random1 ['1']['f1-score'])    \n",
    "#     r1=pd.DataFrame()\n",
    "#     r1['0']= totalF1_0\n",
    "#     r1['1']= totalF1_1\n",
    "#     EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario2\n",
    "#     totalF1_0_2=[]\n",
    "#     totalF1_1_2=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "#         RD2.columns=data[x_column_list].columns\n",
    "#         for col in data[x_column_list].columns:\n",
    "#             dd=np.where(data[x_column_list][col]==0)[0]\n",
    "#             if len(dd)>0:\n",
    "#                 RD2[col][dd]=0\n",
    "#         RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD22.iloc[data_train.index][x_column_list], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD22.iloc[data_val.index][x_column_list])\n",
    "#         report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_2.append(report_Random2['0']['f1-score'])\n",
    "#         totalF1_1_2.append(report_Random2['1']['f1-score'])\n",
    "#     r2=pd.DataFrame()\n",
    "#     r2['0']= totalF1_0_2\n",
    "#     r2['1']= totalF1_1_2\n",
    "#     EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario3\n",
    "#     totalF1_0_3=[]\n",
    "#     totalF1_1_3=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         YR=np.random.permutation(data['y_b'].values)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(data_val[x_column_list])\n",
    "#         report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_3.append(report_Random3['0']['f1-score'])\n",
    "#         totalF1_1_3.append(report_Random3['1']['f1-score'])\n",
    "#     r3=pd.DataFrame()\n",
    "#     r3['0']= totalF1_0_3\n",
    "#     r3['1']= totalF1_1_3\n",
    "#     EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #Senario4\n",
    "#     totalF1_0_4=[]\n",
    "#     totalF1_1_4=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         DR=data[x_column_list].sample(frac=1)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "#         report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_4.append(report_Random4['0']['f1-score'])\n",
    "#         totalF1_1_4.append(report_Random4['1']['f1-score'])\n",
    "#     r4=pd.DataFrame()\n",
    "#     r4['0']= totalF1_0_4\n",
    "#     r4['1']= totalF1_1_4\n",
    "#     EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     ev_value=[EV1,EV2,EV3,EV4]\n",
    "\n",
    "\n",
    "#     return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e006ef1",
   "metadata": {},
   "source": [
    "# Aug DAta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2c28f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scabsuper\n",
      " 1 _ 1 .csv\n",
      "(1000, 240)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(1000, 272)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(953, 557)\n",
      "199\n",
      "[0.0, 0.7989949748743719, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(1000, 110)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      " 1 _ 1 .csv\n",
      "(1000, 44)\n",
      "199\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "path_response='/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/disease_response_aug/'  \n",
    "path_x = '/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/compare_random_aug/'\n",
    "\n",
    "# path_list2 = []\n",
    "# for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "#     for path in dirs:\n",
    "#         path_list2.append(path)\n",
    "# #EV_Value = dict.fromkeys(dirs)\n",
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r') & (file_response[0] != 'O'): \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        #EV_Value[file_response] = dict.fromkeys(dirs)\n",
    "        #writer= pd.ExcelWriter(path_r+'/'+'EV_Value.xlsx', engine='xlsxwriter')\n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                #response.drop(columns=response.columns[2], inplace=True)  \n",
    "                #response=response.drop(columns='Variety2')    \n",
    "                writer= pd.ExcelWriter(path_r+'/'+'EV_Value.xlsx', engine='xlsxwriter')\n",
    "                writer1= pd.ExcelWriter(path_r+'/'+'RMethod1.xlsx', engine='xlsxwriter')\n",
    "                writer2= pd.ExcelWriter(path_r+'/'+'RMethod2.xlsx', engine='xlsxwriter')\n",
    "                writer3= pd.ExcelWriter(path_r+'/'+'RMethod3.xlsx', engine='xlsxwriter')\n",
    "                writer4= pd.ExcelWriter(path_r+'/'+'RMethod4.xlsx', engine='xlsxwriter')\n",
    "                writer5= pd.ExcelWriter(path_r+'/'+'RFresult.xlsx', engine='xlsxwriter')\n",
    "                #writer= pd.ExcelWriter(path_r+'/'+'classification_RF_Random'+'.xlsx', engine='xlsxwriter')   \n",
    "                #EV_Value[file_response] = dict.fromkeys(dirs)\n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(path+'/'+file)  \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID') \n",
    "                                print(data.shape)\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)\n",
    "                                out_random = Compare_random(data,data_train,data_val,cv,NumofR)\n",
    "                                #output_dic[file] = [out_random[0],out_random[1], out_random[2],out_random[3],out_random[4],out_random[5],out_random[6]]\n",
    "                                fig, axs = plt.subplots(1,4, figsize=(20, 10), facecolor='w', edgecolor='k')\n",
    "                                fig.subplots_adjust(hspace =0.1, wspace=0.2)\n",
    "\n",
    "                                plt.subplot(1,4,1)\n",
    "                                r1=out_random[0]\n",
    "                                plt.scatter(r1['0'],r1['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 1')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,2)\n",
    "                                r2=out_random[1]\n",
    "                                plt.scatter(r2['0'],r2['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 2')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,3)\n",
    "                                r3=out_random[2]\n",
    "                                plt.scatter(r3['0'],r3['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 3')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.subplot(1,4,4)\n",
    "                                r4=out_random[3]\n",
    "                                plt.scatter(r4['0'],r4['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0--Strategy 4')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.xlim(0,1)\n",
    "                                plt.ylim(0,1)\n",
    "                                plt.savefig(path_response+file_response+'/'+file_folder+'.png',facecolor='white')\n",
    "                                plt.close()\n",
    "                                print(out_random[4])\n",
    "                                EV_Value= out_random[4]\n",
    "                        pd.DataFrame(EV_Value).to_excel(writer, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r1).to_excel(writer1, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r2).to_excel(writer2, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r3).to_excel(writer3, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame(r4).to_excel(writer4, sheet_name=file_folder, index=True)\n",
    "                        pd.DataFrame([out_random[5],out_random[6]]).to_excel(writer5, sheet_name=file_folder, index=True)\n",
    "                writer.save()\n",
    "                writer1.save()\n",
    "                writer2.save()\n",
    "                writer3.save()\n",
    "                writer4.save()\n",
    "                writer5.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771b91ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_b</th>\n",
       "      <th>IMCC26256</th>\n",
       "      <th>Reyranellales</th>\n",
       "      <th>Nitrospirales</th>\n",
       "      <th>Streptomycetales</th>\n",
       "      <th>Caulobacterales</th>\n",
       "      <th>Solibacterales</th>\n",
       "      <th>Thermomicrobiales</th>\n",
       "      <th>Pseudonocardiales</th>\n",
       "      <th>Haliangiales</th>\n",
       "      <th>...</th>\n",
       "      <th>Glycomycetales</th>\n",
       "      <th>Caedibacterales</th>\n",
       "      <th>C10.SB1A</th>\n",
       "      <th>Phormidesmiales</th>\n",
       "      <th>Candidatus.Doudnabacteria</th>\n",
       "      <th>Ferrovibrionales</th>\n",
       "      <th>Candidatus.Amesbacteria</th>\n",
       "      <th>Candidatus.Zambryskibacteria</th>\n",
       "      <th>Candidatus.Kerfeldbacteria</th>\n",
       "      <th>ADurb.Bin180</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.024721</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.014397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.011521</td>\n",
       "      <td>0.023076</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.026079</td>\n",
       "      <td>0.006361</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.024625</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.006441</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.015449</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015193</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.009792</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.006702</td>\n",
       "      <td>0.009239</td>\n",
       "      <td>0.006967</td>\n",
       "      <td>0.003370</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_b  IMCC26256  Reyranellales  Nitrospirales  Streptomycetales  \\\n",
       "521  1.0   0.001563       0.002131       0.003647          0.014586   \n",
       "737  1.0   0.009573       0.003746       0.003399          0.003295   \n",
       "740  0.0   0.007970       0.006161       0.016916          0.007657   \n",
       "660  0.0   0.014873       0.000594       0.003596          0.012010   \n",
       "411  0.0   0.003839       0.006951       0.026079          0.006361   \n",
       "..   ...        ...            ...            ...               ...   \n",
       "408  1.0   0.005856       0.001952       0.007282          0.001952   \n",
       "332  0.0   0.005215       0.001751       0.006616          0.001790   \n",
       "208  0.0   0.009509       0.001858       0.015449          0.000880   \n",
       "613  1.0   0.015193       0.002613       0.005331          0.011255   \n",
       "78   0.0   0.010337       0.001931       0.011586          0.003597   \n",
       "\n",
       "     Caulobacterales  Solibacterales  Thermomicrobiales  Pseudonocardiales  \\\n",
       "521         0.024721        0.001563           0.014397           0.000000   \n",
       "737         0.009226        0.009573           0.007978           0.010128   \n",
       "740         0.005395        0.011521           0.023076           0.004594   \n",
       "660         0.011591        0.006284           0.004399           0.005586   \n",
       "411         0.007519        0.020286           0.024625           0.008882   \n",
       "..               ...             ...                ...                ...   \n",
       "408         0.007128        0.005023           0.012546           0.007194   \n",
       "332         0.006441        0.004534           0.011150           0.008173   \n",
       "208         0.003178        0.006649           0.006233           0.005329   \n",
       "613         0.007457        0.020559           0.009792           0.003415   \n",
       "78          0.006702        0.009239           0.006967           0.003370   \n",
       "\n",
       "     Haliangiales  ...  Glycomycetales  Caedibacterales  C10.SB1A  \\\n",
       "521      0.001137  ...             0.0         0.000000  0.000000   \n",
       "737      0.008845  ...             0.0         0.000000  0.000000   \n",
       "740      0.005813  ...             0.0         0.000000  0.000000   \n",
       "660      0.003317  ...             0.0         0.000000  0.000000   \n",
       "411      0.005657  ...             0.0         0.000204  0.000000   \n",
       "..            ...  ...             ...              ...       ...   \n",
       "408      0.005461  ...             0.0         0.000000  0.000000   \n",
       "332      0.004806  ...             0.0         0.000000  0.000000   \n",
       "208      0.010365  ...             0.0         0.000000  0.000000   \n",
       "613      0.003833  ...             0.0         0.000000  0.000244   \n",
       "78       0.010337  ...             0.0         0.000000  0.000000   \n",
       "\n",
       "     Phormidesmiales  Candidatus.Doudnabacteria  Ferrovibrionales  \\\n",
       "521              0.0                        0.0          0.000000   \n",
       "737              0.0                        0.0          0.000000   \n",
       "740              0.0                        0.0          0.000000   \n",
       "660              0.0                        0.0          0.000000   \n",
       "411              0.0                        0.0          0.000000   \n",
       "..               ...                        ...               ...   \n",
       "408              0.0                        0.0          0.000000   \n",
       "332              0.0                        0.0          0.000000   \n",
       "208              0.0                        0.0          0.000000   \n",
       "613              0.0                        0.0          0.000000   \n",
       "78               0.0                        0.0          0.000076   \n",
       "\n",
       "     Candidatus.Amesbacteria  Candidatus.Zambryskibacteria  \\\n",
       "521                 0.000000                      0.000000   \n",
       "737                 0.000000                      0.000069   \n",
       "740                 0.000000                      0.000000   \n",
       "660                 0.000000                      0.000000   \n",
       "411                 0.000000                      0.000000   \n",
       "..                       ...                           ...   \n",
       "408                 0.000000                      0.000000   \n",
       "332                 0.000000                      0.000000   \n",
       "208                 0.000171                      0.000000   \n",
       "613                 0.000000                      0.000000   \n",
       "78                  0.000189                      0.000000   \n",
       "\n",
       "     Candidatus.Kerfeldbacteria  ADurb.Bin180  \n",
       "521                    0.000000      0.000000  \n",
       "737                    0.000000      0.000000  \n",
       "740                    0.000000      0.000000  \n",
       "660                    0.000000      0.000000  \n",
       "411                    0.000000      0.000000  \n",
       "..                          ...           ...  \n",
       "408                    0.000000      0.000000  \n",
       "332                    0.000000      0.000000  \n",
       "208                    0.000073      0.000147  \n",
       "613                    0.000000      0.000000  \n",
       "78                     0.000000      0.000000  \n",
       "\n",
       "[200 rows x 239 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ab2233",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_list = data_train.drop(columns=['y_b']).columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db9d27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "param_grid = [\n",
    "{'classifier' : [RandomForestClassifier()],\n",
    "'classifier__criterion':('gini','entropy'),\n",
    "'classifier__class_weight':('balanced','auto')}]\n",
    "clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "best_clf=clf.best_estimator_\n",
    "y_valid=best_clf.predict(data_val[x_column_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7335ef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m F1_0_class_RF\u001b[38;5;241m=\u001b[39m\u001b[43mreport_RF\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m F1_1_class_RF\u001b[38;5;241m=\u001b[39mreport_RF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "F1_0_class_RF=report_RF['0']['f1-score']\n",
    "F1_1_class_RF=report_RF['1']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9e24489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0': {'precision': 0.6160714285714286,\n",
       "  'recall': 0.696969696969697,\n",
       "  'f1-score': 0.6540284360189573,\n",
       "  'support': 99},\n",
       " '1.0': {'precision': 0.6590909090909091,\n",
       "  'recall': 0.5742574257425742,\n",
       "  'f1-score': 0.6137566137566137,\n",
       "  'support': 101},\n",
       " 'accuracy': 0.635,\n",
       " 'macro avg': {'precision': 0.6375811688311688,\n",
       "  'recall': 0.6356135613561356,\n",
       "  'f1-score': 0.6338925248877856,\n",
       "  'support': 200},\n",
       " 'weighted avg': {'precision': 0.6377962662337662,\n",
       "  'recall': 0.635,\n",
       "  'f1-score': 0.6336911657764738,\n",
       "  'support': 200}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28434145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "param_grid = [\n",
    "{'classifier' : [RandomForestClassifier()],\n",
    "'classifier__criterion':('gini','entropy'),\n",
    "'classifier__class_weight':('balanced','auto')}]\n",
    "clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "best_clf=clf.best_estimator_\n",
    "y_valid=best_clf.predict(data_val[x_column_list])\n",
    "\n",
    "report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "F1_0_class_RF=report_RF['0']['f1-score']\n",
    "F1_1_class_RF=report_RF['1']['f1-score']\n",
    "\n",
    "totalF1_0=[]\n",
    "totalF1_1=[]\n",
    "for i in range(1,NumofR):\n",
    "    RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "    RD1=pd.DataFrame(RD1)\n",
    "    RD1.columns =data[x_column_list].columns\n",
    "    RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "    clf.fit(RD11.iloc[data_train.index,0:len(x_column_list)], data_train['y_b'])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(RD11.iloc[data_val.index,0:len(x_column_list)])\n",
    "    report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "    totalF1_0.append(report_Random1 ['0']['f1-score'])\n",
    "    totalF1_1.append(report_Random1 ['1']['f1-score'])    \n",
    "r1=pd.DataFrame()\n",
    "r1['0']= totalF1_0\n",
    "r1['1']= totalF1_1\n",
    "EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#senario2\n",
    "totalF1_0_2=[]\n",
    "totalF1_1_2=[]\n",
    "for i in range(1,NumofR):\n",
    "    RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "    RD2.columns=data[x_column_list].columns\n",
    "    for col in data[x_column_list].columns:\n",
    "        dd=np.where(data[x_column_list][col]==0)[0]\n",
    "        if len(dd)>0:\n",
    "            RD2[col][dd]=0\n",
    "    RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "    clf.fit(RD22.iloc[data_train.index][x_column_list], data_train['y_b'])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(RD22.iloc[data_val.index][x_column_list])\n",
    "    report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "    totalF1_0_2.append(report_Random2['0']['f1-score'])\n",
    "    totalF1_1_2.append(report_Random2['1']['f1-score'])\n",
    "r2=pd.DataFrame()\n",
    "r2['0']= totalF1_0_2\n",
    "r2['1']= totalF1_1_2\n",
    "EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#senario3\n",
    "totalF1_0_3=[]\n",
    "totalF1_1_3=[]\n",
    "for i in range(1,NumofR):\n",
    "    YR=np.random.permutation(data['y_b'].values)\n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "    clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(data_val[x_column_list])\n",
    "    report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "    totalF1_0_3.append(report_Random3['0']['f1-score'])\n",
    "    totalF1_1_3.append(report_Random3['1']['f1-score'])\n",
    "r3=pd.DataFrame()\n",
    "r3['0']= totalF1_0_3\n",
    "r3['1']= totalF1_1_3\n",
    "#print(totalF1_0_3)\n",
    "print(r3.shape[0])\n",
    "\n",
    "EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ (r3.shape[0])\n",
    "#Senario4\n",
    "totalF1_0_4=[]\n",
    "totalF1_1_4=[]\n",
    "for i in range(1,NumofR):\n",
    "    DR=data[x_column_list].sample(frac=1)\n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "    clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "    report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "    totalF1_0_4.append(report_Random4['0']['f1-score'])\n",
    "    totalF1_1_4.append(report_Random4['1']['f1-score'])\n",
    "r4=pd.DataFrame()\n",
    "r4['0']= totalF1_0_4\n",
    "r4['1']= totalF1_1_4\n",
    "EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "ev_value=[EV1,EV2,EV3,EV4]\n",
    "\n",
    "\n",
    "return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
